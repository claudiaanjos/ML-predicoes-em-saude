# Aula 10

**Materiais**

* [Slides](https://edisciplinas.usp.br/pluginfile.php/7418118/mod_resource/content/1/Aula%2015.pdf) utilizados na aula.

* [Artigo](https://arxiv.org/abs/2010.09337) referência da aula: *Interpretable machine learning - a brief history, state-of-the-art and challenges*.

**Aula**

Na aula, abordamos a distinção entre importância preditiva e causalidade, destacando razões para analisar ou, em alguns casos, evitar a análise da importância preditora de variáveis. Exploramos diferentes aspectos da interpretação, incluindo interpretação intrínseca e extrínseca, análise de componentes, sensibilidade à permutação de preditores, aproximações locais e modelos substitutos.

Foi ressaltado que o objetivo principal da predição em machine learning não é compreender a causalidade de um fenômeno, mas sim predizê-lo. A interpretação em machine learning não equivale à causalidade; em vez disso, é uma maneira de compreender como o algoritmo realizou a predição. Além disso, discutimos técnicas específicas, como SHAP values (Shapley Additive Explanations), LIME, incerteza estatística da predição e dependência de variáveis, como meios de aprimorar a interpretação dos resultados preditivos sem assumir causalidade direta.
